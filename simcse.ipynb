{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "商品标题corpus_data = (1001500, 2)\n",
      "用户查询train_data = (100000, 2)\n",
      "查询与商品点击关系qrels = (100000, 2)\n",
      "用户查询test_data = (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "corpus_data = pd.read_csv( \"./data/corpus.tsv\", sep=\"\\t\", names=[\"gid\", \"gname\"])\n",
    "print(f\"商品标题corpus_data = {corpus_data.shape}\")\n",
    "train_data = pd.read_csv(\"./data/train.query.txt\", sep=\"\\t\", names=[\"qid\", \"query\"])\n",
    "print(f\"用户查询train_data = {train_data.shape}\")\n",
    "qrels = pd.read_csv(\"./data/qrels.train.tsv\", sep=\"\\t\", names=[\"qid\", \"gid\"])\n",
    "print(f\"查询与商品点击关系qrels = {qrels.shape}\")\n",
    "test_data = pd.read_csv(\"./data/dev.query.txt\", sep=\"\\t\", names=[\"qid\", \"query\"])\n",
    "print(f\"用户查询test_data = {test_data.shape}\")\n",
    "\n",
    "corpus_data = corpus_data.set_index(\"gid\")\n",
    "train_data = train_data.set_index(\"qid\")\n",
    "qrels = qrels.set_index(\"qid\")\n",
    "test_data = test_data.set_index(\"qid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2corpus = pd.DataFrame(data=corpus_data.loc[qrels.gid]['gname'].values,index=train_data.loc[qrels.index]['query'],columns=['gname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_count(prefix,L):\n",
    "    prefix_l = len(str(prefix))\n",
    "    if L%2==0:\n",
    "        return 10**(L//2-prefix_l)\n",
    "    else:\n",
    "        return 10**(L//2+1-prefix_l)\n",
    "get_count(11,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " 101230032101,\n",
       " 101231132101,\n",
       " 100043340001,\n",
       " 100089980001,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 100048840001,\n",
       " -1,\n",
       " 100044440001]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kthPalindrome(queries, intLength: int):\n",
    "    def get_count(prefix, L):\n",
    "        prefix_l = len(str(prefix))\n",
    "        if L % 2 == 0:\n",
    "            return 10**(L//2-prefix_l)\n",
    "        else:\n",
    "            return 10**(L//2+1-prefix_l)\n",
    "\n",
    "    def get_huiwen(prefix, L):\n",
    "        if L%2 == 0:\n",
    "            prefix = str(prefix)\n",
    "            middle = ''\n",
    "        else:\n",
    "            prefix, middle = str(prefix)[:L//2],str(prefix)[L//2]\n",
    "        s = f'{prefix}{middle}{prefix[::-1]}'\n",
    "        return int(s)\n",
    "\n",
    "    res = []\n",
    "    L = intLength\n",
    "    Max_prefix = 10**(L//2) if L %2 == 0 else 10**(L//2+1)\n",
    "    for q in queries:\n",
    "        prefix = 1\n",
    "        if q>get_count(prefix,L)*10:\n",
    "            res.append(-1)\n",
    "            continue\n",
    "        while q and prefix < Max_prefix:\n",
    "            cnt = get_count(prefix, L)\n",
    "            if q == 1 == cnt:\n",
    "                break\n",
    "            if q > cnt:\n",
    "                prefix += 1\n",
    "                q -= cnt\n",
    "            else:\n",
    "                prefix *= 10\n",
    "        res.append(get_huiwen(prefix, L))\n",
    "    return res\n",
    "queries = [256965477,1231,1232,44,90,519833663,813131855,658305751,49,962390851,45]\n",
    "intLength = 12\n",
    "kthPalindrome(queries,intLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [875,90,209,416,62,647,398,909,669,186,492,748,662,80,414,550,866,358,744,478,19,637,501,129,635,358,867,723,874,454,882,406,360,516,632,883,771,21,358,147,109,472,447,493903904,808,94,645,707,98043237,573,508,142,142,855,498,56,993,355,572,788,977,646,279,821,530,726,631,61,362,136,814,357,105,829909848,645,855,862,635,451,888,609788691,961592349,386,884,536,334,585,71,612]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = [100008747800001,100000898000001,100002080200001,100004151400001,100000616000001,100006464600001,100003979300001,100009080900001,100006686600001,100001858100001,100004919400001,100007474700001,100006616600001,100000797000001,100004131400001,100005494500001,100008656800001,100003575300001,100007434700001,100004777400001,100000181000001,100006363600001,100005000500001,100001282100001,100006343600001,100003575300001,100008666800001,100007222700001,100008737800001,100004535400001,100008818800001,100004050400001,100003595300001,100005151500001,100006313600001,100008828800001,100007707700001,100000202000001,100003575300001,100001464100001,100001080100001,100004717400001,100004464400001,-1,100008070800001,100000939000001,100006444600001,100007060700001,-1,100005727500001,100005070500001,100001414100001,100001414100001,100008545800001,100004979400001,100000555000001,100009929900001,100003545300001,100005717500001,100007878700001,100009767900001,100006454600001,100002787200001,100008202800001,100005292500001,100007252700001,100006303600001,100000606000001,100003616300001,100001353100001,100008131800001,100003565300001,100001040100001,-1,100006444600001,100008545800001,100008616800001,100006343600001,100004505400001,100008878800001,-1,-1,100003858300001,100008838800001,100005353500001,100003333300001,100005848500001,100000707000001,100006111600001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = [100008747800001,100000898000001,100002080200001,100004151400001,100000616000001,100006464600001,100003979300001,100009080900001,100006686600001,100001858100001,100004919400001,100007474700001,100006616600001,100000797000001,100004131400001,100005494500001,100008656800001,100003575300001,100007434700001,100004777400001,100000181000001,100006363600001,100005000500001,100001282100001,100006343600001,100003575300001,100008666800001,100007222700001,100008737800001,100004535400001,100008818800001,100004050400001,100003595300001,100005151500001,100006313600001,100008828800001,100007707700001,100000202000001,100003575300001,100001464100001,100001080100001,100004717400001,100004464400001,-1,100008070800001,100000939000001,100006444600001,100007060700001,180432363234081,100005727500001,100005070500001,100001414100001,100001414100001,100008545800001,100004979400001,100000555000001,100009929900001,100003545300001,100005717500001,100007878700001,100009767900001,100006454600001,100002787200001,100008202800001,100005292500001,100007252700001,100006303600001,100000606000001,100003616300001,100001353100001,100008131800001,100003565300001,100001040100001,-1,100006444600001,100008545800001,100008616800001,100006343600001,100004505400001,100008878800001,-1,-1,100003858300001,100008838800001,100005353500001,100003333300001,100005848500001,100000707000001,100006111600001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mine = [100008747800001,100000898000001,100002080200001,100004151400001,100000616000001,100006464600001,100003979300001,100009080900001,100006686600001,100001858100001,100004919400001,100007474700001,100006616600001,100000797000001,100004131400001,100005494500001,100008656800001,100003575300001,100007434700001,100004777400001,100000181000001,100006363600001,100005000500001,100001282100001,100006343600001,100003575300001,100008666800001,100007222700001,100008737800001,100004535400001,100008818800001,100004050400001,100003595300001,100005151500001,100006313600001,100008828800001,100007707700001,100000202000001,100003575300001,100001464100001,100001080100001,100004717400001,100004464400001,-1,100008070800001,100000939000001,100006444600001,100007060700001,-1,100005727500001,100005070500001,100001414100001,100001414100001,100008545800001,100004979400001,100000555000001,100009929900001,100003545300001,100005717500001,100007878700001,100009767900001,100006454600001,100002787200001,100008202800001,100005292500001,100007252700001,100006303600001,100000606000001,100003616300001,100001353100001,100008131800001,100003565300001,100001040100001,-1,100006444600001,100008545800001,100008616800001,100006343600001,100004505400001,100008878800001,-1,-1,100003858300001,100008838800001,100005353500001,100003333300001,100005848500001,100000707000001,100006111600001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,m,a in zip(input,new_mine,ans):\n",
    "    if a!=m:\n",
    "        print(i,m,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val = train_test_split(query2corpus,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"./data/X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between \"There's a kid on a skateboard.\" and \"A kid is skateboarding.\" is: 0.943\n",
      "Cosine similarity between \"There's a kid on a skateboard.\" and \"A kid is inside the house.\" is: 0.439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2045,  1005,  1055,  1037,  4845,  2006,  1037, 17260,  6277,\n",
       "          1012,   102],\n",
       "        [  101,  1037,  4845,  2003, 17260, 21172,  1012,   102,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  1037,  4845,  2003,  2503,  1996,  2160,  1012,   102,     0,\n",
       "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Import our models. The package will take care of downloading the models automatically\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "# Tokenize input texts\n",
    "texts = [\n",
    "    \"There's a kid on a skateboard.\",\n",
    "    \"A kid is skateboarding.\",\n",
    "    \"A kid is inside the house.\"\n",
    "]\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get the embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output\n",
    "\n",
    "# Calculate cosine similarities\n",
    "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
    "cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])\n",
    "cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], cosine_sim_0_2))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26bec10237431ffccd75b56311d661b39148e6a51398c93462a8a53150f78cf1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
